{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uQCMgpnK9mN",
        "outputId": "fe4598e9-07b9-4552-818f-548b8ae2630c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aCMwmI9WKm5l"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_openml  #fetch_openml()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-XMaxuxL1qr",
        "outputId": "dd2ee0bc-6a09-4ffe-d111-0a2ddd378ee7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xuq7y0S-KvYu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVoOJtq9KvWN"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pj7Q9vNIOkCO",
        "outputId": "c84022ca-350a-4a67-ef2c-ffa35d34574d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "mnist = fetch_openml(\"mnist_784\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mUAAzaYOmcA",
        "outputId": "cba737a6-ffc2-4fcd-de54-de5b793140ad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'data':        pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
              " 0         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              " 1         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              " 2         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              " 3         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              " 4         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              " ...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
              " 69995     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              " 69996     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              " 69997     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              " 69998     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              " 69999     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              " \n",
              "        pixel10  ...  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
              " 0          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
              " 1          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
              " 2          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
              " 3          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
              " 4          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
              " ...        ...  ...       ...       ...       ...       ...       ...   \n",
              " 69995      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
              " 69996      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
              " 69997      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
              " 69998      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
              " 69999      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
              " \n",
              "        pixel780  pixel781  pixel782  pixel783  pixel784  \n",
              " 0           0.0       0.0       0.0       0.0       0.0  \n",
              " 1           0.0       0.0       0.0       0.0       0.0  \n",
              " 2           0.0       0.0       0.0       0.0       0.0  \n",
              " 3           0.0       0.0       0.0       0.0       0.0  \n",
              " 4           0.0       0.0       0.0       0.0       0.0  \n",
              " ...         ...       ...       ...       ...       ...  \n",
              " 69995       0.0       0.0       0.0       0.0       0.0  \n",
              " 69996       0.0       0.0       0.0       0.0       0.0  \n",
              " 69997       0.0       0.0       0.0       0.0       0.0  \n",
              " 69998       0.0       0.0       0.0       0.0       0.0  \n",
              " 69999       0.0       0.0       0.0       0.0       0.0  \n",
              " \n",
              " [70000 rows x 784 columns],\n",
              " 'target': 0        5\n",
              " 1        0\n",
              " 2        4\n",
              " 3        1\n",
              " 4        9\n",
              "         ..\n",
              " 69995    2\n",
              " 69996    3\n",
              " 69997    4\n",
              " 69998    5\n",
              " 69999    6\n",
              " Name: class, Length: 70000, dtype: category\n",
              " Categories (10, object): ['0', '1', '2', '3', ..., '6', '7', '8', '9'],\n",
              " 'frame':        pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
              " 0         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              " 1         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              " 2         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              " 3         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              " 4         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              " ...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
              " 69995     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              " 69996     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              " 69997     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              " 69998     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              " 69999     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              " \n",
              "        pixel10  ...  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
              " 0          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
              " 1          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
              " 2          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
              " 3          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
              " 4          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
              " ...        ...  ...       ...       ...       ...       ...       ...   \n",
              " 69995      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
              " 69996      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
              " 69997      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
              " 69998      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
              " 69999      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
              " \n",
              "        pixel781  pixel782  pixel783  pixel784  class  \n",
              " 0           0.0       0.0       0.0       0.0      5  \n",
              " 1           0.0       0.0       0.0       0.0      0  \n",
              " 2           0.0       0.0       0.0       0.0      4  \n",
              " 3           0.0       0.0       0.0       0.0      1  \n",
              " 4           0.0       0.0       0.0       0.0      9  \n",
              " ...         ...       ...       ...       ...    ...  \n",
              " 69995       0.0       0.0       0.0       0.0      2  \n",
              " 69996       0.0       0.0       0.0       0.0      3  \n",
              " 69997       0.0       0.0       0.0       0.0      4  \n",
              " 69998       0.0       0.0       0.0       0.0      5  \n",
              " 69999       0.0       0.0       0.0       0.0      6  \n",
              " \n",
              " [70000 rows x 785 columns],\n",
              " 'categories': None,\n",
              " 'feature_names': ['pixel1',\n",
              "  'pixel2',\n",
              "  'pixel3',\n",
              "  'pixel4',\n",
              "  'pixel5',\n",
              "  'pixel6',\n",
              "  'pixel7',\n",
              "  'pixel8',\n",
              "  'pixel9',\n",
              "  'pixel10',\n",
              "  'pixel11',\n",
              "  'pixel12',\n",
              "  'pixel13',\n",
              "  'pixel14',\n",
              "  'pixel15',\n",
              "  'pixel16',\n",
              "  'pixel17',\n",
              "  'pixel18',\n",
              "  'pixel19',\n",
              "  'pixel20',\n",
              "  'pixel21',\n",
              "  'pixel22',\n",
              "  'pixel23',\n",
              "  'pixel24',\n",
              "  'pixel25',\n",
              "  'pixel26',\n",
              "  'pixel27',\n",
              "  'pixel28',\n",
              "  'pixel29',\n",
              "  'pixel30',\n",
              "  'pixel31',\n",
              "  'pixel32',\n",
              "  'pixel33',\n",
              "  'pixel34',\n",
              "  'pixel35',\n",
              "  'pixel36',\n",
              "  'pixel37',\n",
              "  'pixel38',\n",
              "  'pixel39',\n",
              "  'pixel40',\n",
              "  'pixel41',\n",
              "  'pixel42',\n",
              "  'pixel43',\n",
              "  'pixel44',\n",
              "  'pixel45',\n",
              "  'pixel46',\n",
              "  'pixel47',\n",
              "  'pixel48',\n",
              "  'pixel49',\n",
              "  'pixel50',\n",
              "  'pixel51',\n",
              "  'pixel52',\n",
              "  'pixel53',\n",
              "  'pixel54',\n",
              "  'pixel55',\n",
              "  'pixel56',\n",
              "  'pixel57',\n",
              "  'pixel58',\n",
              "  'pixel59',\n",
              "  'pixel60',\n",
              "  'pixel61',\n",
              "  'pixel62',\n",
              "  'pixel63',\n",
              "  'pixel64',\n",
              "  'pixel65',\n",
              "  'pixel66',\n",
              "  'pixel67',\n",
              "  'pixel68',\n",
              "  'pixel69',\n",
              "  'pixel70',\n",
              "  'pixel71',\n",
              "  'pixel72',\n",
              "  'pixel73',\n",
              "  'pixel74',\n",
              "  'pixel75',\n",
              "  'pixel76',\n",
              "  'pixel77',\n",
              "  'pixel78',\n",
              "  'pixel79',\n",
              "  'pixel80',\n",
              "  'pixel81',\n",
              "  'pixel82',\n",
              "  'pixel83',\n",
              "  'pixel84',\n",
              "  'pixel85',\n",
              "  'pixel86',\n",
              "  'pixel87',\n",
              "  'pixel88',\n",
              "  'pixel89',\n",
              "  'pixel90',\n",
              "  'pixel91',\n",
              "  'pixel92',\n",
              "  'pixel93',\n",
              "  'pixel94',\n",
              "  'pixel95',\n",
              "  'pixel96',\n",
              "  'pixel97',\n",
              "  'pixel98',\n",
              "  'pixel99',\n",
              "  'pixel100',\n",
              "  'pixel101',\n",
              "  'pixel102',\n",
              "  'pixel103',\n",
              "  'pixel104',\n",
              "  'pixel105',\n",
              "  'pixel106',\n",
              "  'pixel107',\n",
              "  'pixel108',\n",
              "  'pixel109',\n",
              "  'pixel110',\n",
              "  'pixel111',\n",
              "  'pixel112',\n",
              "  'pixel113',\n",
              "  'pixel114',\n",
              "  'pixel115',\n",
              "  'pixel116',\n",
              "  'pixel117',\n",
              "  'pixel118',\n",
              "  'pixel119',\n",
              "  'pixel120',\n",
              "  'pixel121',\n",
              "  'pixel122',\n",
              "  'pixel123',\n",
              "  'pixel124',\n",
              "  'pixel125',\n",
              "  'pixel126',\n",
              "  'pixel127',\n",
              "  'pixel128',\n",
              "  'pixel129',\n",
              "  'pixel130',\n",
              "  'pixel131',\n",
              "  'pixel132',\n",
              "  'pixel133',\n",
              "  'pixel134',\n",
              "  'pixel135',\n",
              "  'pixel136',\n",
              "  'pixel137',\n",
              "  'pixel138',\n",
              "  'pixel139',\n",
              "  'pixel140',\n",
              "  'pixel141',\n",
              "  'pixel142',\n",
              "  'pixel143',\n",
              "  'pixel144',\n",
              "  'pixel145',\n",
              "  'pixel146',\n",
              "  'pixel147',\n",
              "  'pixel148',\n",
              "  'pixel149',\n",
              "  'pixel150',\n",
              "  'pixel151',\n",
              "  'pixel152',\n",
              "  'pixel153',\n",
              "  'pixel154',\n",
              "  'pixel155',\n",
              "  'pixel156',\n",
              "  'pixel157',\n",
              "  'pixel158',\n",
              "  'pixel159',\n",
              "  'pixel160',\n",
              "  'pixel161',\n",
              "  'pixel162',\n",
              "  'pixel163',\n",
              "  'pixel164',\n",
              "  'pixel165',\n",
              "  'pixel166',\n",
              "  'pixel167',\n",
              "  'pixel168',\n",
              "  'pixel169',\n",
              "  'pixel170',\n",
              "  'pixel171',\n",
              "  'pixel172',\n",
              "  'pixel173',\n",
              "  'pixel174',\n",
              "  'pixel175',\n",
              "  'pixel176',\n",
              "  'pixel177',\n",
              "  'pixel178',\n",
              "  'pixel179',\n",
              "  'pixel180',\n",
              "  'pixel181',\n",
              "  'pixel182',\n",
              "  'pixel183',\n",
              "  'pixel184',\n",
              "  'pixel185',\n",
              "  'pixel186',\n",
              "  'pixel187',\n",
              "  'pixel188',\n",
              "  'pixel189',\n",
              "  'pixel190',\n",
              "  'pixel191',\n",
              "  'pixel192',\n",
              "  'pixel193',\n",
              "  'pixel194',\n",
              "  'pixel195',\n",
              "  'pixel196',\n",
              "  'pixel197',\n",
              "  'pixel198',\n",
              "  'pixel199',\n",
              "  'pixel200',\n",
              "  'pixel201',\n",
              "  'pixel202',\n",
              "  'pixel203',\n",
              "  'pixel204',\n",
              "  'pixel205',\n",
              "  'pixel206',\n",
              "  'pixel207',\n",
              "  'pixel208',\n",
              "  'pixel209',\n",
              "  'pixel210',\n",
              "  'pixel211',\n",
              "  'pixel212',\n",
              "  'pixel213',\n",
              "  'pixel214',\n",
              "  'pixel215',\n",
              "  'pixel216',\n",
              "  'pixel217',\n",
              "  'pixel218',\n",
              "  'pixel219',\n",
              "  'pixel220',\n",
              "  'pixel221',\n",
              "  'pixel222',\n",
              "  'pixel223',\n",
              "  'pixel224',\n",
              "  'pixel225',\n",
              "  'pixel226',\n",
              "  'pixel227',\n",
              "  'pixel228',\n",
              "  'pixel229',\n",
              "  'pixel230',\n",
              "  'pixel231',\n",
              "  'pixel232',\n",
              "  'pixel233',\n",
              "  'pixel234',\n",
              "  'pixel235',\n",
              "  'pixel236',\n",
              "  'pixel237',\n",
              "  'pixel238',\n",
              "  'pixel239',\n",
              "  'pixel240',\n",
              "  'pixel241',\n",
              "  'pixel242',\n",
              "  'pixel243',\n",
              "  'pixel244',\n",
              "  'pixel245',\n",
              "  'pixel246',\n",
              "  'pixel247',\n",
              "  'pixel248',\n",
              "  'pixel249',\n",
              "  'pixel250',\n",
              "  'pixel251',\n",
              "  'pixel252',\n",
              "  'pixel253',\n",
              "  'pixel254',\n",
              "  'pixel255',\n",
              "  'pixel256',\n",
              "  'pixel257',\n",
              "  'pixel258',\n",
              "  'pixel259',\n",
              "  'pixel260',\n",
              "  'pixel261',\n",
              "  'pixel262',\n",
              "  'pixel263',\n",
              "  'pixel264',\n",
              "  'pixel265',\n",
              "  'pixel266',\n",
              "  'pixel267',\n",
              "  'pixel268',\n",
              "  'pixel269',\n",
              "  'pixel270',\n",
              "  'pixel271',\n",
              "  'pixel272',\n",
              "  'pixel273',\n",
              "  'pixel274',\n",
              "  'pixel275',\n",
              "  'pixel276',\n",
              "  'pixel277',\n",
              "  'pixel278',\n",
              "  'pixel279',\n",
              "  'pixel280',\n",
              "  'pixel281',\n",
              "  'pixel282',\n",
              "  'pixel283',\n",
              "  'pixel284',\n",
              "  'pixel285',\n",
              "  'pixel286',\n",
              "  'pixel287',\n",
              "  'pixel288',\n",
              "  'pixel289',\n",
              "  'pixel290',\n",
              "  'pixel291',\n",
              "  'pixel292',\n",
              "  'pixel293',\n",
              "  'pixel294',\n",
              "  'pixel295',\n",
              "  'pixel296',\n",
              "  'pixel297',\n",
              "  'pixel298',\n",
              "  'pixel299',\n",
              "  'pixel300',\n",
              "  'pixel301',\n",
              "  'pixel302',\n",
              "  'pixel303',\n",
              "  'pixel304',\n",
              "  'pixel305',\n",
              "  'pixel306',\n",
              "  'pixel307',\n",
              "  'pixel308',\n",
              "  'pixel309',\n",
              "  'pixel310',\n",
              "  'pixel311',\n",
              "  'pixel312',\n",
              "  'pixel313',\n",
              "  'pixel314',\n",
              "  'pixel315',\n",
              "  'pixel316',\n",
              "  'pixel317',\n",
              "  'pixel318',\n",
              "  'pixel319',\n",
              "  'pixel320',\n",
              "  'pixel321',\n",
              "  'pixel322',\n",
              "  'pixel323',\n",
              "  'pixel324',\n",
              "  'pixel325',\n",
              "  'pixel326',\n",
              "  'pixel327',\n",
              "  'pixel328',\n",
              "  'pixel329',\n",
              "  'pixel330',\n",
              "  'pixel331',\n",
              "  'pixel332',\n",
              "  'pixel333',\n",
              "  'pixel334',\n",
              "  'pixel335',\n",
              "  'pixel336',\n",
              "  'pixel337',\n",
              "  'pixel338',\n",
              "  'pixel339',\n",
              "  'pixel340',\n",
              "  'pixel341',\n",
              "  'pixel342',\n",
              "  'pixel343',\n",
              "  'pixel344',\n",
              "  'pixel345',\n",
              "  'pixel346',\n",
              "  'pixel347',\n",
              "  'pixel348',\n",
              "  'pixel349',\n",
              "  'pixel350',\n",
              "  'pixel351',\n",
              "  'pixel352',\n",
              "  'pixel353',\n",
              "  'pixel354',\n",
              "  'pixel355',\n",
              "  'pixel356',\n",
              "  'pixel357',\n",
              "  'pixel358',\n",
              "  'pixel359',\n",
              "  'pixel360',\n",
              "  'pixel361',\n",
              "  'pixel362',\n",
              "  'pixel363',\n",
              "  'pixel364',\n",
              "  'pixel365',\n",
              "  'pixel366',\n",
              "  'pixel367',\n",
              "  'pixel368',\n",
              "  'pixel369',\n",
              "  'pixel370',\n",
              "  'pixel371',\n",
              "  'pixel372',\n",
              "  'pixel373',\n",
              "  'pixel374',\n",
              "  'pixel375',\n",
              "  'pixel376',\n",
              "  'pixel377',\n",
              "  'pixel378',\n",
              "  'pixel379',\n",
              "  'pixel380',\n",
              "  'pixel381',\n",
              "  'pixel382',\n",
              "  'pixel383',\n",
              "  'pixel384',\n",
              "  'pixel385',\n",
              "  'pixel386',\n",
              "  'pixel387',\n",
              "  'pixel388',\n",
              "  'pixel389',\n",
              "  'pixel390',\n",
              "  'pixel391',\n",
              "  'pixel392',\n",
              "  'pixel393',\n",
              "  'pixel394',\n",
              "  'pixel395',\n",
              "  'pixel396',\n",
              "  'pixel397',\n",
              "  'pixel398',\n",
              "  'pixel399',\n",
              "  'pixel400',\n",
              "  'pixel401',\n",
              "  'pixel402',\n",
              "  'pixel403',\n",
              "  'pixel404',\n",
              "  'pixel405',\n",
              "  'pixel406',\n",
              "  'pixel407',\n",
              "  'pixel408',\n",
              "  'pixel409',\n",
              "  'pixel410',\n",
              "  'pixel411',\n",
              "  'pixel412',\n",
              "  'pixel413',\n",
              "  'pixel414',\n",
              "  'pixel415',\n",
              "  'pixel416',\n",
              "  'pixel417',\n",
              "  'pixel418',\n",
              "  'pixel419',\n",
              "  'pixel420',\n",
              "  'pixel421',\n",
              "  'pixel422',\n",
              "  'pixel423',\n",
              "  'pixel424',\n",
              "  'pixel425',\n",
              "  'pixel426',\n",
              "  'pixel427',\n",
              "  'pixel428',\n",
              "  'pixel429',\n",
              "  'pixel430',\n",
              "  'pixel431',\n",
              "  'pixel432',\n",
              "  'pixel433',\n",
              "  'pixel434',\n",
              "  'pixel435',\n",
              "  'pixel436',\n",
              "  'pixel437',\n",
              "  'pixel438',\n",
              "  'pixel439',\n",
              "  'pixel440',\n",
              "  'pixel441',\n",
              "  'pixel442',\n",
              "  'pixel443',\n",
              "  'pixel444',\n",
              "  'pixel445',\n",
              "  'pixel446',\n",
              "  'pixel447',\n",
              "  'pixel448',\n",
              "  'pixel449',\n",
              "  'pixel450',\n",
              "  'pixel451',\n",
              "  'pixel452',\n",
              "  'pixel453',\n",
              "  'pixel454',\n",
              "  'pixel455',\n",
              "  'pixel456',\n",
              "  'pixel457',\n",
              "  'pixel458',\n",
              "  'pixel459',\n",
              "  'pixel460',\n",
              "  'pixel461',\n",
              "  'pixel462',\n",
              "  'pixel463',\n",
              "  'pixel464',\n",
              "  'pixel465',\n",
              "  'pixel466',\n",
              "  'pixel467',\n",
              "  'pixel468',\n",
              "  'pixel469',\n",
              "  'pixel470',\n",
              "  'pixel471',\n",
              "  'pixel472',\n",
              "  'pixel473',\n",
              "  'pixel474',\n",
              "  'pixel475',\n",
              "  'pixel476',\n",
              "  'pixel477',\n",
              "  'pixel478',\n",
              "  'pixel479',\n",
              "  'pixel480',\n",
              "  'pixel481',\n",
              "  'pixel482',\n",
              "  'pixel483',\n",
              "  'pixel484',\n",
              "  'pixel485',\n",
              "  'pixel486',\n",
              "  'pixel487',\n",
              "  'pixel488',\n",
              "  'pixel489',\n",
              "  'pixel490',\n",
              "  'pixel491',\n",
              "  'pixel492',\n",
              "  'pixel493',\n",
              "  'pixel494',\n",
              "  'pixel495',\n",
              "  'pixel496',\n",
              "  'pixel497',\n",
              "  'pixel498',\n",
              "  'pixel499',\n",
              "  'pixel500',\n",
              "  'pixel501',\n",
              "  'pixel502',\n",
              "  'pixel503',\n",
              "  'pixel504',\n",
              "  'pixel505',\n",
              "  'pixel506',\n",
              "  'pixel507',\n",
              "  'pixel508',\n",
              "  'pixel509',\n",
              "  'pixel510',\n",
              "  'pixel511',\n",
              "  'pixel512',\n",
              "  'pixel513',\n",
              "  'pixel514',\n",
              "  'pixel515',\n",
              "  'pixel516',\n",
              "  'pixel517',\n",
              "  'pixel518',\n",
              "  'pixel519',\n",
              "  'pixel520',\n",
              "  'pixel521',\n",
              "  'pixel522',\n",
              "  'pixel523',\n",
              "  'pixel524',\n",
              "  'pixel525',\n",
              "  'pixel526',\n",
              "  'pixel527',\n",
              "  'pixel528',\n",
              "  'pixel529',\n",
              "  'pixel530',\n",
              "  'pixel531',\n",
              "  'pixel532',\n",
              "  'pixel533',\n",
              "  'pixel534',\n",
              "  'pixel535',\n",
              "  'pixel536',\n",
              "  'pixel537',\n",
              "  'pixel538',\n",
              "  'pixel539',\n",
              "  'pixel540',\n",
              "  'pixel541',\n",
              "  'pixel542',\n",
              "  'pixel543',\n",
              "  'pixel544',\n",
              "  'pixel545',\n",
              "  'pixel546',\n",
              "  'pixel547',\n",
              "  'pixel548',\n",
              "  'pixel549',\n",
              "  'pixel550',\n",
              "  'pixel551',\n",
              "  'pixel552',\n",
              "  'pixel553',\n",
              "  'pixel554',\n",
              "  'pixel555',\n",
              "  'pixel556',\n",
              "  'pixel557',\n",
              "  'pixel558',\n",
              "  'pixel559',\n",
              "  'pixel560',\n",
              "  'pixel561',\n",
              "  'pixel562',\n",
              "  'pixel563',\n",
              "  'pixel564',\n",
              "  'pixel565',\n",
              "  'pixel566',\n",
              "  'pixel567',\n",
              "  'pixel568',\n",
              "  'pixel569',\n",
              "  'pixel570',\n",
              "  'pixel571',\n",
              "  'pixel572',\n",
              "  'pixel573',\n",
              "  'pixel574',\n",
              "  'pixel575',\n",
              "  'pixel576',\n",
              "  'pixel577',\n",
              "  'pixel578',\n",
              "  'pixel579',\n",
              "  'pixel580',\n",
              "  'pixel581',\n",
              "  'pixel582',\n",
              "  'pixel583',\n",
              "  'pixel584',\n",
              "  'pixel585',\n",
              "  'pixel586',\n",
              "  'pixel587',\n",
              "  'pixel588',\n",
              "  'pixel589',\n",
              "  'pixel590',\n",
              "  'pixel591',\n",
              "  'pixel592',\n",
              "  'pixel593',\n",
              "  'pixel594',\n",
              "  'pixel595',\n",
              "  'pixel596',\n",
              "  'pixel597',\n",
              "  'pixel598',\n",
              "  'pixel599',\n",
              "  'pixel600',\n",
              "  'pixel601',\n",
              "  'pixel602',\n",
              "  'pixel603',\n",
              "  'pixel604',\n",
              "  'pixel605',\n",
              "  'pixel606',\n",
              "  'pixel607',\n",
              "  'pixel608',\n",
              "  'pixel609',\n",
              "  'pixel610',\n",
              "  'pixel611',\n",
              "  'pixel612',\n",
              "  'pixel613',\n",
              "  'pixel614',\n",
              "  'pixel615',\n",
              "  'pixel616',\n",
              "  'pixel617',\n",
              "  'pixel618',\n",
              "  'pixel619',\n",
              "  'pixel620',\n",
              "  'pixel621',\n",
              "  'pixel622',\n",
              "  'pixel623',\n",
              "  'pixel624',\n",
              "  'pixel625',\n",
              "  'pixel626',\n",
              "  'pixel627',\n",
              "  'pixel628',\n",
              "  'pixel629',\n",
              "  'pixel630',\n",
              "  'pixel631',\n",
              "  'pixel632',\n",
              "  'pixel633',\n",
              "  'pixel634',\n",
              "  'pixel635',\n",
              "  'pixel636',\n",
              "  'pixel637',\n",
              "  'pixel638',\n",
              "  'pixel639',\n",
              "  'pixel640',\n",
              "  'pixel641',\n",
              "  'pixel642',\n",
              "  'pixel643',\n",
              "  'pixel644',\n",
              "  'pixel645',\n",
              "  'pixel646',\n",
              "  'pixel647',\n",
              "  'pixel648',\n",
              "  'pixel649',\n",
              "  'pixel650',\n",
              "  'pixel651',\n",
              "  'pixel652',\n",
              "  'pixel653',\n",
              "  'pixel654',\n",
              "  'pixel655',\n",
              "  'pixel656',\n",
              "  'pixel657',\n",
              "  'pixel658',\n",
              "  'pixel659',\n",
              "  'pixel660',\n",
              "  'pixel661',\n",
              "  'pixel662',\n",
              "  'pixel663',\n",
              "  'pixel664',\n",
              "  'pixel665',\n",
              "  'pixel666',\n",
              "  'pixel667',\n",
              "  'pixel668',\n",
              "  'pixel669',\n",
              "  'pixel670',\n",
              "  'pixel671',\n",
              "  'pixel672',\n",
              "  'pixel673',\n",
              "  'pixel674',\n",
              "  'pixel675',\n",
              "  'pixel676',\n",
              "  'pixel677',\n",
              "  'pixel678',\n",
              "  'pixel679',\n",
              "  'pixel680',\n",
              "  'pixel681',\n",
              "  'pixel682',\n",
              "  'pixel683',\n",
              "  'pixel684',\n",
              "  'pixel685',\n",
              "  'pixel686',\n",
              "  'pixel687',\n",
              "  'pixel688',\n",
              "  'pixel689',\n",
              "  'pixel690',\n",
              "  'pixel691',\n",
              "  'pixel692',\n",
              "  'pixel693',\n",
              "  'pixel694',\n",
              "  'pixel695',\n",
              "  'pixel696',\n",
              "  'pixel697',\n",
              "  'pixel698',\n",
              "  'pixel699',\n",
              "  'pixel700',\n",
              "  'pixel701',\n",
              "  'pixel702',\n",
              "  'pixel703',\n",
              "  'pixel704',\n",
              "  'pixel705',\n",
              "  'pixel706',\n",
              "  'pixel707',\n",
              "  'pixel708',\n",
              "  'pixel709',\n",
              "  'pixel710',\n",
              "  'pixel711',\n",
              "  'pixel712',\n",
              "  'pixel713',\n",
              "  'pixel714',\n",
              "  'pixel715',\n",
              "  'pixel716',\n",
              "  'pixel717',\n",
              "  'pixel718',\n",
              "  'pixel719',\n",
              "  'pixel720',\n",
              "  'pixel721',\n",
              "  'pixel722',\n",
              "  'pixel723',\n",
              "  'pixel724',\n",
              "  'pixel725',\n",
              "  'pixel726',\n",
              "  'pixel727',\n",
              "  'pixel728',\n",
              "  'pixel729',\n",
              "  'pixel730',\n",
              "  'pixel731',\n",
              "  'pixel732',\n",
              "  'pixel733',\n",
              "  'pixel734',\n",
              "  'pixel735',\n",
              "  'pixel736',\n",
              "  'pixel737',\n",
              "  'pixel738',\n",
              "  'pixel739',\n",
              "  'pixel740',\n",
              "  'pixel741',\n",
              "  'pixel742',\n",
              "  'pixel743',\n",
              "  'pixel744',\n",
              "  'pixel745',\n",
              "  'pixel746',\n",
              "  'pixel747',\n",
              "  'pixel748',\n",
              "  'pixel749',\n",
              "  'pixel750',\n",
              "  'pixel751',\n",
              "  'pixel752',\n",
              "  'pixel753',\n",
              "  'pixel754',\n",
              "  'pixel755',\n",
              "  'pixel756',\n",
              "  'pixel757',\n",
              "  'pixel758',\n",
              "  'pixel759',\n",
              "  'pixel760',\n",
              "  'pixel761',\n",
              "  'pixel762',\n",
              "  'pixel763',\n",
              "  'pixel764',\n",
              "  'pixel765',\n",
              "  'pixel766',\n",
              "  'pixel767',\n",
              "  'pixel768',\n",
              "  'pixel769',\n",
              "  'pixel770',\n",
              "  'pixel771',\n",
              "  'pixel772',\n",
              "  'pixel773',\n",
              "  'pixel774',\n",
              "  'pixel775',\n",
              "  'pixel776',\n",
              "  'pixel777',\n",
              "  'pixel778',\n",
              "  'pixel779',\n",
              "  'pixel780',\n",
              "  'pixel781',\n",
              "  'pixel782',\n",
              "  'pixel783',\n",
              "  'pixel784'],\n",
              " 'target_names': ['class'],\n",
              " 'DESCR': \"**Author**: Yann LeCun, Corinna Cortes, Christopher J.C. Burges  \\n**Source**: [MNIST Website](http://yann.lecun.com/exdb/mnist/) - Date unknown  \\n**Please cite**:  \\n\\nThe MNIST database of handwritten digits with 784 features, raw data available at: http://yann.lecun.com/exdb/mnist/. It can be split in a training set of the first 60,000 examples, and a test set of 10,000 examples  \\n\\nIt is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image. It is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting. The original black and white (bilevel) images from NIST were size normalized to fit in a 20x20 pixel box while preserving their aspect ratio. The resulting images contain grey levels as a result of the anti-aliasing technique used by the normalization algorithm. the images were centered in a 28x28 image by computing the center of mass of the pixels, and translating the image so as to position this point at the center of the 28x28 field.  \\n\\nWith some classification methods (particularly template-based methods, such as SVM and K-nearest neighbors), the error rate improves when the digits are centered by bounding box rather than center of mass. If you do this kind of pre-processing, you should report it in your publications. The MNIST database was constructed from NIST's NIST originally designated SD-3 as their training set and SD-1 as their test set. However, SD-3 is much cleaner and easier to recognize than SD-1. The reason for this can be found on the fact that SD-3 was collected among Census Bureau employees, while SD-1 was collected among high-school students. Drawing sensible conclusions from learning experiments requires that the result be independent of the choice of training set and test among the complete set of samples. Therefore it was necessary to build a new database by mixing NIST's datasets.  \\n\\nThe MNIST training set is composed of 30,000 patterns from SD-3 and 30,000 patterns from SD-1. Our test set was composed of 5,000 patterns from SD-3 and 5,000 patterns from SD-1. The 60,000 pattern training set contained examples from approximately 250 writers. We made sure that the sets of writers of the training set and test set were disjoint. SD-1 contains 58,527 digit images written by 500 different writers. In contrast to SD-3, where blocks of data from each writer appeared in sequence, the data in SD-1 is scrambled. Writer identities for SD-1 is available and we used this information to unscramble the writers. We then split SD-1 in two: characters written by the first 250 writers went into our new training set. The remaining 250 writers were placed in our test set. Thus we had two sets with nearly 30,000 examples each. The new training set was completed with enough examples from SD-3, starting at pattern # 0, to make a full set of 60,000 training patterns. Similarly, the new test set was completed with SD-3 examples starting at pattern # 35,000 to make a full set with 60,000 test patterns. Only a subset of 10,000 test images (5,000 from SD-1 and 5,000 from SD-3) is available on this site. The full 60,000 sample training set is available.\\n\\nDownloaded from openml.org.\",\n",
              " 'details': {'id': '554',\n",
              "  'name': 'mnist_784',\n",
              "  'version': '1',\n",
              "  'description_version': '2',\n",
              "  'format': 'ARFF',\n",
              "  'creator': ['Yann LeCun', 'Corinna Cortes', 'Christopher J.C. Burges'],\n",
              "  'upload_date': '2014-09-29T03:28:38',\n",
              "  'language': 'English',\n",
              "  'licence': 'Public',\n",
              "  'url': 'https://api.openml.org/data/v1/download/52667/mnist_784.arff',\n",
              "  'parquet_url': 'http://openml1.win.tue.nl/dataset554/dataset_554.pq',\n",
              "  'file_id': '52667',\n",
              "  'default_target_attribute': 'class',\n",
              "  'tag': ['AzurePilot',\n",
              "   'OpenML-CC18',\n",
              "   'OpenML100',\n",
              "   'study_1',\n",
              "   'study_123',\n",
              "   'study_41',\n",
              "   'study_99',\n",
              "   'vision'],\n",
              "  'visibility': 'public',\n",
              "  'minio_url': 'http://openml1.win.tue.nl/dataset554/dataset_554.pq',\n",
              "  'status': 'active',\n",
              "  'processing_date': '2020-11-20 20:12:09',\n",
              "  'md5_checksum': '0298d579eb1b86163de7723944c7e495'},\n",
              " 'url': 'https://www.openml.org/d/554'}"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mnist\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UuTPrFroQcPY"
      },
      "outputs": [],
      "source": [
        "X,y=mnist['data'],mnist['target']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIyeJCa4Qrzs",
        "outputId": "3a471b39-8c91-43ce-9957-562783c8e284"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(70000, 784)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Qg1ESO1Qwjg",
        "outputId": "86a3e243-d18b-4f93-b6cc-f68bf50a38c7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(70000,)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ms76w6PzQzTG"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__f82d1PQ4W1"
      },
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGWz_wKvR-hY"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import mnist\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZJK2X-0SyZU",
        "outputId": "3346f5de-7f6a-4e79-dabb-f9ca93e5b66d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<function keras.src.datasets.mnist.load_data(path='mnist.npz')>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mnist.load_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3Si4qGySyV2",
        "outputId": "e57c3df4-3790-4830-e548-74f2cfe6d6e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(X_train, y_train), (X_test, y_test)=mnist.load_data()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWy4cC_4SyTY",
        "outputId": "af30bca9-4945-4bdd-e820-ff5fa4b0f41b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((60000, 28, 28), (10000, 28, 28), (60000,), (10000,))"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-YqeZR1DSyQ0"
      },
      "outputs": [],
      "source": [
        "def plot_input_img(i):\n",
        "    plt.imshow(X_train[i], cmap='binary')\n",
        "    plt.title(y_train[i])\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3zGaE7EcUKgT",
        "outputId": "d568e53b-b7ca-4d5f-f7e1-2d44f72763a5"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGzCAYAAABpdMNsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAdU0lEQVR4nO3db3BU5dnH8V9AsgImm4aQfxIwoIAKpFOUNIMiljR/2jIgTCtqW3AYKBocMbV0sCJq7ZOKU+toA75pQ21FqFOBkRdYjCbRNkFBGUptI8mkgiUJSCfZECCh5H5eMG67EsSz7ObKhu9n5syQ3XNnL49n8uUkm0Occ84JAIA+Nsh6AADApYkAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgoI/s2bNHRUVFSkxMVEJCggoKCrR3717rsQAzcdwLDoi+9957T9OnT1dWVpZ+8IMfqKenR+vWrdO///1vvfPOO5owYYL1iECfI0BAH/jmN7+p2tpaHThwQCNGjJAkNTc3a/z48SooKNAf//hH4wmBvse34IA+8NZbbyk/Pz8YH0nKyMjQLbfcou3bt+v48eOG0wE2CBDQB7q6ujR06NBzHh82bJi6u7u1f/9+g6kAWwQI6AMTJkxQXV2dzpw5E3ysu7tbu3btkiT961//shoNMEOAgD5w77336sMPP9TixYv1wQcfaP/+/fr+97+v5uZmSdLJkyeNJwT6HgEC+sCyZcv00EMPaePGjbr++us1efJkNTY2auXKlZKkK664wnhCoO8RIKCP/OxnP1Nra6veeust7du3T++++656enokSePHjzeeDuh7vA0bMDRt2jQ1Nzfro48+0qBB/H0QlxbOeMDI5s2b9e6772rFihXEB5ckroCAPlBTU6PHH39cBQUFGjFihOrq6lRRUaGvf/3revXVV3XZZZdZjwj0Oc56oA9ceeWVGjx4sJ566il1dHQoOztbTzzxhEpLS4kPLllcAQEATPCNZwCACQIEADBBgAAAJggQAMAEAQIAmCBAAAAT/e4XEHp6enT48GElJCQoLi7OehwAgEfOOXV0dCgzM/Nz7/LR7wJ0+PBhZWVlWY8BALhIhw4d0qhRo877fL8LUEJCgqSzgycmJhpPAwDwKhAIKCsrK/j1/HyiFqDy8nI99dRTamlpUU5Ojp577jlNmzbtgus+/bZbYmIiAQKAGHahH6NE5U0ImzdvVmlpqdasWaP33ntPOTk5Kiws1JEjR6LxcgCAGBSVAD399NNasmSJ7r77bl133XV6/vnnNWzYMP3mN7+JxssBAGJQxAPU3d2tPXv2KD8//78vMmiQ8vPzVVtbe87+XV1dCgQCIRsAYOCLeIA++eQTnTlzRmlpaSGPp6WlqaWl5Zz9y8rK5Pf7gxvvgAOAS4P5L6KuWrVK7e3twe3QoUPWIwEA+kDE3wWXkpKiwYMHq7W1NeTx1tZWpaenn7O/z+eTz+eL9BgAgH4u4ldA8fHxmjp1qiorK4OP9fT0qLKyUnl5eZF+OQBAjIrK7wGVlpZq4cKFuuGGGzRt2jQ988wz6uzs1N133x2NlwMAxKCoBOj222/X0aNH9cgjj6ilpUVf/vKXtWPHjnPemAAAuHTFOeec9RD/KxAIyO/3q729nTshAEAM+qJfx83fBQcAuDQRIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATEQ/Qo48+qri4uJBt4sSJkX4ZAECMuywan/T666/X66+//t8XuSwqLwMAiGFRKcNll12m9PT0aHxqAMAAEZWfAR04cECZmZkaO3as7rrrLh08ePC8+3Z1dSkQCIRsAICBL+IBys3N1YYNG7Rjxw6tX79eTU1Nuvnmm9XR0dHr/mVlZfL7/cEtKysr0iMBAPqhOOeci+YLtLW1acyYMXr66ae1ePHic57v6upSV1dX8ONAIKCsrCy1t7crMTExmqMBAKIgEAjI7/df8Ot41N8dkJSUpPHjx6uhoaHX530+n3w+X7THAAD0M1H/PaDjx4+rsbFRGRkZ0X4pAEAMiXiAHnzwQVVXV+uf//yn/vKXv+i2227T4MGDdccdd0T6pQAAMSzi34L7+OOPdccdd+jYsWMaOXKkbrrpJtXV1WnkyJGRfikAQAyLeIA2bdoU6U8JABiAuBccAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGAi6v8gHRBLdu3a5XnN7373O89rampqPK/Zv3+/5zXh+sUvfuF5TWZmpuc1b731luc13/ve9zyvyc3N9bwG0ccVEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAExwN2wMSJs3bw5r3f333+95zdGjRz2vcc55XjNz5kzPaz755BPPayTpwQcfDGudV+Ech3D+mzZt2uR5DaKPKyAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQ3I0Wf+s9//uN5zbvvvut5zZIlSzyvkaTOzk7Pa2655RbPa1avXu15zU033eR5TVdXl+c1kvSd73zH85rXXnstrNfy6oYbbuiT10H0cQUEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJjgZqToU7///e89r1m8eHEUJuldQUGB5zWbN2/2vCYxMdHzmnCEM5vUdzcWzcrK8rxm4cKFUZgEFrgCAgCYIEAAABOeA1RTU6PZs2crMzNTcXFx2rp1a8jzzjk98sgjysjI0NChQ5Wfn68DBw5Eal4AwADhOUCdnZ3KyclReXl5r8+vXbtWzz77rJ5//nnt2rVLw4cPV2FhoU6dOnXRwwIABg7Pb0IoLi5WcXFxr8855/TMM8/o4Ycf1pw5cyRJL7zwgtLS0rR161YtWLDg4qYFAAwYEf0ZUFNTk1paWpSfnx98zO/3Kzc3V7W1tb2u6erqUiAQCNkAAANfRAPU0tIiSUpLSwt5PC0tLfjcZ5WVlcnv9we3cN6WCQCIPebvglu1apXa29uD26FDh6xHAgD0gYgGKD09XZLU2toa8nhra2vwuc/y+XxKTEwM2QAAA19EA5Sdna309HRVVlYGHwsEAtq1a5fy8vIi+VIAgBjn+V1wx48fV0NDQ/DjpqYm7d27V8nJyRo9erRWrFihJ554Qtdcc42ys7O1evVqZWZmau7cuZGcGwAQ4zwHaPfu3br11luDH5eWlko6e3+mDRs2aOXKlers7NTSpUvV1tamm266STt27NDll18euakBADEvzjnnrIf4X4FAQH6/X+3t7fw8qJ97+OGHPa/5v//7P89r4uLiPK8pKSnxvEaSnnjiCc9r+vN5eu2114a17sMPP4zwJL175ZVXPK/59HcM0X990a/j5u+CAwBcmggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGDC8z/HgIHn8ccfD2tdOHe29vl8ntcUFhZ6XvPkk096XiNJQ4cODWudV6dOnfK85k9/+pPnNR999JHnNZIUzk3yV69e7XkNd7a+tHEFBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCY4GakA0xbW5vnNevWrQvrteLi4jyvCefGolu3bvW8pi81NDR4XnPXXXd5XrN7927Pa8L17W9/2/OalStXRmESDGRcAQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJrgZ6QDT3d3tec3Ro0ejMEnvnn32Wc9rjhw54nlNRUWF5zWStG3bNs9r/va3v3le09HR4XlNODd/HTQovL9jfve73/W8Zvjw4WG9Fi5dXAEBAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACa4GekAEx8f73lNampqWK8Vzk1Cr7rqKs9rwrkJZ1+68sorPa9JTEz0vObw4cOe16SkpHheI0mzZ88Oax3gBVdAAAATBAgAYMJzgGpqajR79mxlZmYqLi5OW7duDXl+0aJFiouLC9mKiooiNS8AYIDwHKDOzk7l5OSovLz8vPsUFRWpubk5uL300ksXNSQAYODx/CaE4uJiFRcXf+4+Pp9P6enpYQ8FABj4ovIzoKqqKqWmpmrChAm65557dOzYsfPu29XVpUAgELIBAAa+iAeoqKhIL7zwgiorK/Xkk0+qurpaxcXFOnPmTK/7l5WVye/3B7esrKxIjwQA6Ici/ntACxYsCP558uTJmjJlisaNG6eqqirNmjXrnP1XrVql0tLS4MeBQIAIAcAlIOpvwx47dqxSUlLU0NDQ6/M+n0+JiYkhGwBg4It6gD7++GMdO3ZMGRkZ0X4pAEAM8fwtuOPHj4dczTQ1NWnv3r1KTk5WcnKyHnvsMc2fP1/p6elqbGzUypUrdfXVV6uwsDCigwMAYpvnAO3evVu33npr8ONPf36zcOFCrV+/Xvv27dNvf/tbtbW1KTMzUwUFBfrpT38qn88XuakBADHPc4Bmzpwp59x5n3/ttdcuaiBcnKSkJM9rPns3iy/qW9/6luc1n/eW/PO5+uqrPa+ZM2eO5zXS2Tt5eJWcnOx5zf++WeeLCudmpOG8DtBXuBccAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATET8n+RG7MnNzQ1r3dGjRyM8SWyqqanxvKa6utrzmri4OM9rxo4d63kN0Fe4AgIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATHAzUuAinTx50vOacG4sGs6aBQsWeF4D9BWugAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAE9yMFLhIhYWF1iMAMYkrIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABDcjBS7Sa6+9Zj0CEJO4AgIAmCBAAAATngJUVlamG2+8UQkJCUpNTdXcuXNVX18fss+pU6dUUlKiESNG6IorrtD8+fPV2toa0aEBALHPU4Cqq6tVUlKiuro67dy5U6dPn1ZBQYE6OzuD+zzwwAN69dVX9fLLL6u6ulqHDx/WvHnzIj44ACC2eXoTwo4dO0I+3rBhg1JTU7Vnzx7NmDFD7e3t+vWvf62NGzfqa1/7miSpoqJC1157rerq6vTVr341cpMDAGLaRf0MqL29XZKUnJwsSdqzZ49Onz6t/Pz84D4TJ07U6NGjVVtb2+vn6OrqUiAQCNkAAANf2AHq6enRihUrNH36dE2aNEmS1NLSovj4eCUlJYXsm5aWppaWll4/T1lZmfx+f3DLysoKdyQAQAwJO0AlJSXav3+/Nm3adFEDrFq1Su3t7cHt0KFDF/X5AACxIaxfRF2+fLm2b9+umpoajRo1Kvh4enq6uru71dbWFnIV1NraqvT09F4/l8/nk8/nC2cMAEAM83QF5JzT8uXLtWXLFr3xxhvKzs4OeX7q1KkaMmSIKisrg4/V19fr4MGDysvLi8zEAIABwdMVUElJiTZu3Kht27YpISEh+HMdv9+voUOHyu/3a/HixSotLVVycrISExN13333KS8vj3fAAQBCeArQ+vXrJUkzZ84MebyiokKLFi2SJP3yl7/UoEGDNH/+fHV1damwsFDr1q2LyLAAgIHDU4Cccxfc5/LLL1d5ebnKy8vDHgqIJY2NjdYjADGJe8EBAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADARFj/IiqA/7r55ps9r/kid5YHBjqugAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAE9yMFLhIkydP9rzmmmuu8bymsbGxT9ZI0siRI8NaB3jBFRAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIKbkQIGHnroIc9rFi9e3CevI0m/+tWvPK+57rrrwnotXLq4AgIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATHAzUsDAvHnzPK/ZtGmT5zU7d+70vEaSHn30Uc9rKioqPK8ZPny45zUYOLgCAgCYIEAAABOeAlRWVqYbb7xRCQkJSk1N1dy5c1VfXx+yz8yZMxUXFxeyLVu2LKJDAwBin6cAVVdXq6SkRHV1ddq5c6dOnz6tgoICdXZ2huy3ZMkSNTc3B7e1a9dGdGgAQOzz9CaEHTt2hHy8YcMGpaamas+ePZoxY0bw8WHDhik9PT0yEwIABqSL+hlQe3u7JCk5OTnk8RdffFEpKSmaNGmSVq1apRMnTpz3c3R1dSkQCIRsAICBL+y3Yff09GjFihWaPn26Jk2aFHz8zjvv1JgxY5SZmal9+/bpxz/+serr6/XKK6/0+nnKysr02GOPhTsGACBGhR2gkpIS7d+/X2+//XbI40uXLg3+efLkycrIyNCsWbPU2NiocePGnfN5Vq1apdLS0uDHgUBAWVlZ4Y4FAIgRYQVo+fLl2r59u2pqajRq1KjP3Tc3N1eS1NDQ0GuAfD6ffD5fOGMAAGKYpwA553Tfffdpy5YtqqqqUnZ29gXX7N27V5KUkZER1oAAgIHJU4BKSkq0ceNGbdu2TQkJCWppaZEk+f1+DR06VI2Njdq4caO+8Y1vaMSIEdq3b58eeOABzZgxQ1OmTInKfwAAIDZ5CtD69eslnf1l0/9VUVGhRYsWKT4+Xq+//rqeeeYZdXZ2KisrS/Pnz9fDDz8csYEBAAOD52/BfZ6srCxVV1df1EAAgEtDnLtQVfpYIBCQ3+9Xe3u7EhMTrccB+o1wfkfuJz/5SVivtW7dOs9r/vrXv3pec91113leg/7vi34d52akAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJbkYKAIgobkYKAOjXCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmLjMeoDP+vTWdIFAwHgSAEA4Pv36faFbjfa7AHV0dEiSsrKyjCcBAFyMjo4O+f3+8z7f7+6G3dPTo8OHDyshIUFxcXEhzwUCAWVlZenQoUOX9J2yOQ5ncRzO4jicxXE4qz8cB+ecOjo6lJmZqUGDzv+Tnn53BTRo0CCNGjXqc/dJTEy8pE+wT3EczuI4nMVxOIvjcJb1cfi8K59P8SYEAIAJAgQAMBFTAfL5fFqzZo18Pp/1KKY4DmdxHM7iOJzFcTgrlo5Dv3sTAgDg0hBTV0AAgIGDAAEATBAgAIAJAgQAMEGAAAAmYiZA5eXluuqqq3T55ZcrNzdX77zzjvVIfe7RRx9VXFxcyDZx4kTrsaKupqZGs2fPVmZmpuLi4rR169aQ551zeuSRR5SRkaGhQ4cqPz9fBw4csBk2ii50HBYtWnTO+VFUVGQzbJSUlZXpxhtvVEJCglJTUzV37lzV19eH7HPq1CmVlJRoxIgRuuKKKzR//ny1trYaTRwdX+Q4zJw585zzYdmyZUYT9y4mArR582aVlpZqzZo1eu+995STk6PCwkIdOXLEerQ+d/3116u5uTm4vf3229YjRV1nZ6dycnJUXl7e6/Nr167Vs88+q+eff167du3S8OHDVVhYqFOnTvXxpNF1oeMgSUVFRSHnx0svvdSHE0ZfdXW1SkpKVFdXp507d+r06dMqKChQZ2dncJ8HHnhAr776ql5++WVVV1fr8OHDmjdvnuHUkfdFjoMkLVmyJOR8WLt2rdHE5+FiwLRp01xJSUnw4zNnzrjMzExXVlZmOFXfW7NmjcvJybEew5Qkt2XLluDHPT09Lj093T311FPBx9ra2pzP53MvvfSSwYR947PHwTnnFi5c6ObMmWMyj5UjR444Sa66uto5d/b//ZAhQ9zLL78c3Ofvf/+7k+Rqa2utxoy6zx4H55y75ZZb3P3332831BfQ76+Auru7tWfPHuXn5wcfGzRokPLz81VbW2s4mY0DBw4oMzNTY8eO1V133aWDBw9aj2SqqalJLS0tIeeH3+9Xbm7uJXl+VFVVKTU1VRMmTNA999yjY8eOWY8UVe3t7ZKk5ORkSdKePXt0+vTpkPNh4sSJGj169IA+Hz57HD714osvKiUlRZMmTdKqVat04sQJi/HOq9/dDfuzPvnkE505c0ZpaWkhj6elpekf//iH0VQ2cnNztWHDBk2YMEHNzc167LHHdPPNN2v//v1KSEiwHs9ES0uLJPV6fnz63KWiqKhI8+bNU3Z2thobG/XQQw+puLhYtbW1Gjx4sPV4EdfT06MVK1Zo+vTpmjRpkqSz50N8fLySkpJC9h3I50Nvx0GS7rzzTo0ZM0aZmZnat2+ffvzjH6u+vl6vvPKK4bSh+n2A8F/FxcXBP0+ZMkW5ubkaM2aM/vCHP2jx4sWGk6E/WLBgQfDPkydP1pQpUzRu3DhVVVVp1qxZhpNFR0lJifbv339J/Bz085zvOCxdujT458mTJysjI0OzZs1SY2Ojxo0b19dj9qrffwsuJSVFgwcPPuddLK2trUpPTzeaqn9ISkrS+PHj1dDQYD2KmU/PAc6Pc40dO1YpKSkD8vxYvny5tm/frjfffDPk3w9LT09Xd3e32traQvYfqOfD+Y5Db3JzcyWpX50P/T5A8fHxmjp1qiorK4OP9fT0qLKyUnl5eYaT2Tt+/LgaGxuVkZFhPYqZ7Oxspaenh5wfgUBAu3btuuTPj48//ljHjh0bUOeHc07Lly/Xli1b9MYbbyg7Ozvk+alTp2rIkCEh50N9fb0OHjw4oM6HCx2H3uzdu1eS+tf5YP0uiC9i06ZNzufzuQ0bNrgPPvjALV261CUlJbmWlhbr0frUD3/4Q1dVVeWamprcn//8Z5efn+9SUlLckSNHrEeLqo6ODvf++++7999/30lyTz/9tHv//ffdRx995Jxz7uc//7lLSkpy27Ztc/v27XNz5sxx2dnZ7uTJk8aTR9bnHYeOjg734IMPutraWtfU1ORef/1195WvfMVdc8017tSpU9ajR8w999zj/H6/q6qqcs3NzcHtxIkTwX2WLVvmRo8e7d544w23e/dul5eX5/Ly8gynjrwLHYeGhgb3+OOPu927d7umpia3bds2N3bsWDdjxgzjyUPFRICcc+65555zo0ePdvHx8W7atGmurq7OeqQ+d/vtt7uMjAwXHx/vrrzySnf77be7hoYG67Gi7s0333SSztkWLlzonDv7VuzVq1e7tLQ05/P53KxZs1x9fb3t0FHwecfhxIkTrqCgwI0cOdINGTLEjRkzxi1ZsmTA/SWtt/9+Sa6ioiK4z8mTJ929997rvvSlL7lhw4a52267zTU3N9sNHQUXOg4HDx50M2bMcMnJyc7n87mrr77a/ehHP3Lt7e22g38G/x4QAMBEv/8ZEABgYCJAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGDi/wHH3VO4J9wLPAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "for i in range(5):\n",
        "    plot_input_img(i)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rK7MXzrUczr"
      },
      "source": [
        "Preprocess the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUlMG3LhSyOM"
      },
      "outputs": [],
      "source": [
        "#normalizing the image to [0, 1] range\n",
        "X_train=X_train.astype(np.float32)/255\n",
        "X_test=X_test.astype(np.float32)/255\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C7H4axfDSyLy"
      },
      "outputs": [],
      "source": [
        "X_train=np.expand_dims(X_train, -1)  #expand\n",
        "X_test=np.expand_dims(X_test, -1)   #(60000, 28, 28, 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LsaORIfSyI4",
        "outputId": "1cc5d307-7f26-45cc-b498-64a68e799414"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtEVnipmVnZE"
      },
      "source": [
        "OneHotVector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPSfkCutSyGf"
      },
      "outputs": [],
      "source": [
        "y_train =keras.utils.to_categorical(y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTaijVYuSyEC",
        "outputId": "4219df93-f74a-4f3f-fd11-c0c607267c5a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train  #only whereever the value is present it will show the 1 there\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mOM4LAbtSyBr"
      },
      "outputs": [],
      "source": [
        "y_test =keras.utils.to_categorical(y_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4K85f6MWOXs"
      },
      "source": [
        "###To buils the model we have to import the libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueq0F_pgSx_F",
        "outputId": "b480e344-b927-47d8-ce2e-d3e8159c576a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 13, 13, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 5, 5, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1600)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1600)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                16010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 34826 (136.04 KB)\n",
            "Trainable params: 34826 (136.04 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model=Sequential()\n",
        "model.add(Conv2D(32, (3,3), input_shape=(28, 28,1), activation='relu'))\n",
        "model.add(MaxPool2D((2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3,3), activation='relu'))\n",
        "model.add(MaxPool2D((2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jRBEt8tjSx8h"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss=keras.losses.categorical_crossentropy, metrics=['accuracy'] )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5BuLEj44Sx6O"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "es = EarlyStopping(monitor='val_acc', min_delta=0.01, patience=4, verbose=1)\n",
        "mc = ModelCheckpoint((\"./bestmodel.h5\"), monitor=\"val_acc\", verbose=1, save_best_only=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2X3Zy81CSx31",
        "outputId": "e099001b-24e3-4646-d122-54127793a3df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1313/1313 [==============================] - 66s 48ms/step - loss: 0.2142 - accuracy: 0.9354 - val_loss: 0.0754 - val_accuracy: 0.9768\n",
            "Epoch 2/50\n",
            "1313/1313 [==============================] - 42s 32ms/step - loss: 0.0707 - accuracy: 0.9784 - val_loss: 0.0570 - val_accuracy: 0.9824\n",
            "Epoch 3/50\n",
            "1313/1313 [==============================] - 43s 33ms/step - loss: 0.0520 - accuracy: 0.9834 - val_loss: 0.0553 - val_accuracy: 0.9837\n",
            "Epoch 4/50\n",
            "1313/1313 [==============================] - 40s 31ms/step - loss: 0.0437 - accuracy: 0.9859 - val_loss: 0.0429 - val_accuracy: 0.9867\n",
            "Epoch 5/50\n",
            "1313/1313 [==============================] - 40s 31ms/step - loss: 0.0364 - accuracy: 0.9885 - val_loss: 0.0516 - val_accuracy: 0.9845\n",
            "Epoch 6/50\n",
            "1313/1313 [==============================] - 41s 31ms/step - loss: 0.0324 - accuracy: 0.9892 - val_loss: 0.0462 - val_accuracy: 0.9862\n",
            "Epoch 7/50\n",
            "1313/1313 [==============================] - 45s 35ms/step - loss: 0.0273 - accuracy: 0.9915 - val_loss: 0.0409 - val_accuracy: 0.9889\n",
            "Epoch 8/50\n",
            "1313/1313 [==============================] - 44s 34ms/step - loss: 0.0250 - accuracy: 0.9918 - val_loss: 0.0412 - val_accuracy: 0.9885\n",
            "Epoch 9/50\n",
            "1313/1313 [==============================] - 40s 31ms/step - loss: 0.0203 - accuracy: 0.9932 - val_loss: 0.0495 - val_accuracy: 0.9866\n",
            "Epoch 10/50\n",
            "1313/1313 [==============================] - 41s 31ms/step - loss: 0.0206 - accuracy: 0.9934 - val_loss: 0.0430 - val_accuracy: 0.9881\n",
            "Epoch 11/50\n",
            "1313/1313 [==============================] - 45s 34ms/step - loss: 0.0180 - accuracy: 0.9935 - val_loss: 0.0393 - val_accuracy: 0.9895\n",
            "Epoch 12/50\n",
            "1313/1313 [==============================] - 40s 31ms/step - loss: 0.0156 - accuracy: 0.9943 - val_loss: 0.0455 - val_accuracy: 0.9891\n",
            "Epoch 13/50\n",
            "1313/1313 [==============================] - 41s 31ms/step - loss: 0.0153 - accuracy: 0.9945 - val_loss: 0.0412 - val_accuracy: 0.9897\n",
            "Epoch 14/50\n",
            "1313/1313 [==============================] - 40s 31ms/step - loss: 0.0135 - accuracy: 0.9952 - val_loss: 0.0435 - val_accuracy: 0.9886\n",
            "Epoch 15/50\n",
            "1313/1313 [==============================] - 41s 31ms/step - loss: 0.0128 - accuracy: 0.9953 - val_loss: 0.0459 - val_accuracy: 0.9892\n",
            "Epoch 16/50\n",
            "1313/1313 [==============================] - 46s 35ms/step - loss: 0.0125 - accuracy: 0.9958 - val_loss: 0.0429 - val_accuracy: 0.9900\n",
            "Epoch 17/50\n",
            "1313/1313 [==============================] - 42s 32ms/step - loss: 0.0130 - accuracy: 0.9951 - val_loss: 0.0430 - val_accuracy: 0.9900\n",
            "Epoch 18/50\n",
            "1313/1313 [==============================] - 45s 35ms/step - loss: 0.0117 - accuracy: 0.9958 - val_loss: 0.0472 - val_accuracy: 0.9889\n",
            "Epoch 19/50\n",
            "1313/1313 [==============================] - 42s 32ms/step - loss: 0.0102 - accuracy: 0.9965 - val_loss: 0.0453 - val_accuracy: 0.9896\n",
            "Epoch 20/50\n",
            "1313/1313 [==============================] - 41s 31ms/step - loss: 0.0091 - accuracy: 0.9968 - val_loss: 0.0454 - val_accuracy: 0.9907\n",
            "Epoch 21/50\n",
            "1313/1313 [==============================] - 41s 32ms/step - loss: 0.0103 - accuracy: 0.9966 - val_loss: 0.0461 - val_accuracy: 0.9892\n",
            "Epoch 22/50\n",
            "1313/1313 [==============================] - 44s 33ms/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 0.0424 - val_accuracy: 0.9903\n",
            "Epoch 23/50\n",
            "1313/1313 [==============================] - 43s 33ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 0.0446 - val_accuracy: 0.9897\n",
            "Epoch 24/50\n",
            "1313/1313 [==============================] - 44s 33ms/step - loss: 0.0077 - accuracy: 0.9972 - val_loss: 0.0517 - val_accuracy: 0.9894\n",
            "Epoch 25/50\n",
            "1313/1313 [==============================] - 43s 32ms/step - loss: 0.0083 - accuracy: 0.9971 - val_loss: 0.0457 - val_accuracy: 0.9900\n",
            "Epoch 26/50\n",
            "1313/1313 [==============================] - 41s 31ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 0.0501 - val_accuracy: 0.9895\n",
            "Epoch 27/50\n",
            "1313/1313 [==============================] - 42s 32ms/step - loss: 0.0088 - accuracy: 0.9971 - val_loss: 0.0456 - val_accuracy: 0.9908\n",
            "Epoch 28/50\n",
            "1313/1313 [==============================] - 41s 31ms/step - loss: 0.0078 - accuracy: 0.9973 - val_loss: 0.0500 - val_accuracy: 0.9893\n",
            "Epoch 29/50\n",
            "1313/1313 [==============================] - 43s 32ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.0496 - val_accuracy: 0.9896\n",
            "Epoch 30/50\n",
            "1313/1313 [==============================] - 42s 32ms/step - loss: 0.0074 - accuracy: 0.9975 - val_loss: 0.0467 - val_accuracy: 0.9911\n",
            "Epoch 31/50\n",
            "1313/1313 [==============================] - 41s 31ms/step - loss: 0.0064 - accuracy: 0.9972 - val_loss: 0.0549 - val_accuracy: 0.9901\n",
            "Epoch 32/50\n",
            "1313/1313 [==============================] - 42s 32ms/step - loss: 0.0072 - accuracy: 0.9975 - val_loss: 0.0515 - val_accuracy: 0.9906\n",
            "Epoch 33/50\n",
            "1313/1313 [==============================] - 40s 30ms/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.0549 - val_accuracy: 0.9893\n",
            "Epoch 34/50\n",
            "1313/1313 [==============================] - 46s 35ms/step - loss: 0.0060 - accuracy: 0.9980 - val_loss: 0.0562 - val_accuracy: 0.9900\n",
            "Epoch 35/50\n",
            "1313/1313 [==============================] - 41s 31ms/step - loss: 0.0072 - accuracy: 0.9974 - val_loss: 0.0571 - val_accuracy: 0.9902\n",
            "Epoch 36/50\n",
            "1313/1313 [==============================] - 42s 32ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.0494 - val_accuracy: 0.9912\n",
            "Epoch 37/50\n",
            "1313/1313 [==============================] - 42s 32ms/step - loss: 0.0066 - accuracy: 0.9977 - val_loss: 0.0579 - val_accuracy: 0.9899\n",
            "Epoch 38/50\n",
            "1313/1313 [==============================] - 41s 31ms/step - loss: 0.0062 - accuracy: 0.9978 - val_loss: 0.0544 - val_accuracy: 0.9908\n",
            "Epoch 39/50\n",
            "1313/1313 [==============================] - 41s 31ms/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.0561 - val_accuracy: 0.9913\n",
            "Epoch 40/50\n",
            "1313/1313 [==============================] - 41s 31ms/step - loss: 0.0062 - accuracy: 0.9978 - val_loss: 0.0498 - val_accuracy: 0.9911\n",
            "Epoch 41/50\n",
            "1313/1313 [==============================] - 45s 34ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.0546 - val_accuracy: 0.9908\n",
            "Epoch 42/50\n",
            "1313/1313 [==============================] - 42s 32ms/step - loss: 0.0066 - accuracy: 0.9978 - val_loss: 0.0529 - val_accuracy: 0.9908\n",
            "Epoch 43/50\n",
            "1313/1313 [==============================] - 42s 32ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.0523 - val_accuracy: 0.9908\n",
            "Epoch 44/50\n",
            "1313/1313 [==============================] - 40s 31ms/step - loss: 0.0066 - accuracy: 0.9977 - val_loss: 0.0564 - val_accuracy: 0.9911\n",
            "Epoch 45/50\n",
            "1313/1313 [==============================] - 42s 32ms/step - loss: 0.0071 - accuracy: 0.9978 - val_loss: 0.0554 - val_accuracy: 0.9903\n",
            "Epoch 46/50\n",
            "1313/1313 [==============================] - 46s 35ms/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 0.0516 - val_accuracy: 0.9912\n",
            "Epoch 47/50\n",
            "1313/1313 [==============================] - 41s 32ms/step - loss: 0.0045 - accuracy: 0.9982 - val_loss: 0.0602 - val_accuracy: 0.9898\n",
            "Epoch 48/50\n",
            "1313/1313 [==============================] - 41s 31ms/step - loss: 0.0054 - accuracy: 0.9985 - val_loss: 0.0583 - val_accuracy: 0.9906\n",
            "Epoch 49/50\n",
            "1313/1313 [==============================] - 41s 32ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.0537 - val_accuracy: 0.9908\n",
            "Epoch 50/50\n",
            "1313/1313 [==============================] - 41s 31ms/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 0.0595 - val_accuracy: 0.9902\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ce664f0eda0>"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X_train, y_train, epochs=50, validation_split=0.3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsEdS7N7jzBt",
        "outputId": "cdd9df57-d1f4-4644-9df7-754941cb4379"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "model_s = model.save(\"./bestmodel.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ot9SqRq6l3hB"
      },
      "outputs": [],
      "source": [
        "model_s=keras.models.load_model(\"./bestmodel.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9t59SMbbkCSj",
        "outputId": "55c363fe-9fb5-40b2-974f-6206c10bcc65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0497 - accuracy: 0.9910\n",
            "the model accuracy is 0.9909999966621399\n"
          ]
        }
      ],
      "source": [
        "score=model_s.evaluate(X_test, y_test)\n",
        "print(f\"the model accuracy is {score[1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRXwvICGlGSh",
        "outputId": "9106bd13-f8ca-438f-9383-f1e39c45ce90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1750/1750 [==============================] - ETA: 0s - loss: 0.1779 - accuracy: 0.9455"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 54s 30ms/step - loss: 0.1779 - accuracy: 0.9455 - val_loss: 0.0663 - val_accuracy: 0.9793\n",
            "Epoch 2/50\n",
            "1750/1750 [==============================] - ETA: 0s - loss: 0.0633 - accuracy: 0.9800"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 52s 30ms/step - loss: 0.0633 - accuracy: 0.9800 - val_loss: 0.0476 - val_accuracy: 0.9854\n",
            "Epoch 3/50\n",
            "1749/1750 [============================>.] - ETA: 0s - loss: 0.0469 - accuracy: 0.9852"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 54s 31ms/step - loss: 0.0469 - accuracy: 0.9852 - val_loss: 0.0424 - val_accuracy: 0.9869\n",
            "Epoch 4/50\n",
            "1750/1750 [==============================] - ETA: 0s - loss: 0.0390 - accuracy: 0.9881"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 52s 30ms/step - loss: 0.0390 - accuracy: 0.9881 - val_loss: 0.0375 - val_accuracy: 0.9895\n",
            "Epoch 5/50\n",
            "1750/1750 [==============================] - ETA: 0s - loss: 0.0332 - accuracy: 0.9895"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 51s 29ms/step - loss: 0.0332 - accuracy: 0.9895 - val_loss: 0.0400 - val_accuracy: 0.9886\n",
            "Epoch 6/50\n",
            "1750/1750 [==============================] - ETA: 0s - loss: 0.0291 - accuracy: 0.9902"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 52s 30ms/step - loss: 0.0291 - accuracy: 0.9902 - val_loss: 0.0330 - val_accuracy: 0.9906\n",
            "Epoch 7/50\n",
            "1750/1750 [==============================] - ETA: 0s - loss: 0.0263 - accuracy: 0.9917"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 51s 29ms/step - loss: 0.0263 - accuracy: 0.9917 - val_loss: 0.0341 - val_accuracy: 0.9908\n",
            "Epoch 8/50\n",
            "1749/1750 [============================>.] - ETA: 0s - loss: 0.0221 - accuracy: 0.9927"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 54s 31ms/step - loss: 0.0221 - accuracy: 0.9927 - val_loss: 0.0338 - val_accuracy: 0.9910\n",
            "Epoch 9/50\n",
            "1750/1750 [==============================] - ETA: 0s - loss: 0.0201 - accuracy: 0.9934"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 52s 30ms/step - loss: 0.0201 - accuracy: 0.9934 - val_loss: 0.0372 - val_accuracy: 0.9901\n",
            "Epoch 10/50\n",
            "1749/1750 [============================>.] - ETA: 0s - loss: 0.0174 - accuracy: 0.9940"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 53s 30ms/step - loss: 0.0174 - accuracy: 0.9940 - val_loss: 0.0382 - val_accuracy: 0.9901\n",
            "Epoch 11/50\n",
            "1750/1750 [==============================] - ETA: 0s - loss: 0.0186 - accuracy: 0.9937"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 51s 29ms/step - loss: 0.0186 - accuracy: 0.9937 - val_loss: 0.0359 - val_accuracy: 0.9916\n",
            "Epoch 12/50\n",
            "1748/1750 [============================>.] - ETA: 0s - loss: 0.0157 - accuracy: 0.9948"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 54s 31ms/step - loss: 0.0157 - accuracy: 0.9948 - val_loss: 0.0342 - val_accuracy: 0.9915\n",
            "Epoch 13/50\n",
            "1750/1750 [==============================] - ETA: 0s - loss: 0.0151 - accuracy: 0.9948"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 52s 29ms/step - loss: 0.0151 - accuracy: 0.9948 - val_loss: 0.0376 - val_accuracy: 0.9906\n",
            "Epoch 14/50\n",
            "1750/1750 [==============================] - ETA: 0s - loss: 0.0142 - accuracy: 0.9953"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 52s 30ms/step - loss: 0.0142 - accuracy: 0.9953 - val_loss: 0.0392 - val_accuracy: 0.9900\n",
            "Epoch 15/50\n",
            "1749/1750 [============================>.] - ETA: 0s - loss: 0.0145 - accuracy: 0.9952"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 54s 31ms/step - loss: 0.0145 - accuracy: 0.9952 - val_loss: 0.0347 - val_accuracy: 0.9912\n",
            "Epoch 16/50\n",
            "1748/1750 [============================>.] - ETA: 0s - loss: 0.0130 - accuracy: 0.9957"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 51s 29ms/step - loss: 0.0129 - accuracy: 0.9957 - val_loss: 0.0375 - val_accuracy: 0.9903\n",
            "Epoch 17/50\n",
            "1749/1750 [============================>.] - ETA: 0s - loss: 0.0131 - accuracy: 0.9956"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 53s 30ms/step - loss: 0.0131 - accuracy: 0.9956 - val_loss: 0.0333 - val_accuracy: 0.9915\n",
            "Epoch 18/50\n",
            "1749/1750 [============================>.] - ETA: 0s - loss: 0.0109 - accuracy: 0.9960"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 52s 30ms/step - loss: 0.0109 - accuracy: 0.9960 - val_loss: 0.0338 - val_accuracy: 0.9913\n",
            "Epoch 19/50\n",
            "1750/1750 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 0.9957"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 54s 31ms/step - loss: 0.0115 - accuracy: 0.9957 - val_loss: 0.0355 - val_accuracy: 0.9912\n",
            "Epoch 20/50\n",
            "1749/1750 [============================>.] - ETA: 0s - loss: 0.0094 - accuracy: 0.9967"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 53s 30ms/step - loss: 0.0094 - accuracy: 0.9967 - val_loss: 0.0388 - val_accuracy: 0.9912\n",
            "Epoch 21/50\n",
            "1749/1750 [============================>.] - ETA: 0s - loss: 0.0108 - accuracy: 0.9961"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 56s 32ms/step - loss: 0.0108 - accuracy: 0.9961 - val_loss: 0.0335 - val_accuracy: 0.9924\n",
            "Epoch 22/50\n",
            "1750/1750 [==============================] - ETA: 0s - loss: 0.0098 - accuracy: 0.9966"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 53s 31ms/step - loss: 0.0098 - accuracy: 0.9966 - val_loss: 0.0374 - val_accuracy: 0.9919\n",
            "Epoch 23/50\n",
            "1748/1750 [============================>.] - ETA: 0s - loss: 0.0100 - accuracy: 0.9965"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 53s 30ms/step - loss: 0.0100 - accuracy: 0.9965 - val_loss: 0.0374 - val_accuracy: 0.9916\n",
            "Epoch 24/50\n",
            "1749/1750 [============================>.] - ETA: 0s - loss: 0.0089 - accuracy: 0.9971"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 53s 30ms/step - loss: 0.0089 - accuracy: 0.9971 - val_loss: 0.0385 - val_accuracy: 0.9912\n",
            "Epoch 25/50\n",
            "1750/1750 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 0.9971"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 50s 29ms/step - loss: 0.0082 - accuracy: 0.9971 - val_loss: 0.0431 - val_accuracy: 0.9914\n",
            "Epoch 26/50\n",
            "1750/1750 [==============================] - ETA: 0s - loss: 0.0077 - accuracy: 0.9971"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 52s 30ms/step - loss: 0.0077 - accuracy: 0.9971 - val_loss: 0.0403 - val_accuracy: 0.9918\n",
            "Epoch 27/50\n",
            "1750/1750 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 0.9973"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 52s 30ms/step - loss: 0.0079 - accuracy: 0.9973 - val_loss: 0.0427 - val_accuracy: 0.9916\n",
            "Epoch 28/50\n",
            "1749/1750 [============================>.] - ETA: 0s - loss: 0.0076 - accuracy: 0.9974"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 50s 29ms/step - loss: 0.0076 - accuracy: 0.9974 - val_loss: 0.0416 - val_accuracy: 0.9927\n",
            "Epoch 29/50\n",
            "1749/1750 [============================>.] - ETA: 0s - loss: 0.0086 - accuracy: 0.9971"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 54s 31ms/step - loss: 0.0086 - accuracy: 0.9971 - val_loss: 0.0445 - val_accuracy: 0.9905\n",
            "Epoch 30/50\n",
            "1749/1750 [============================>.] - ETA: 0s - loss: 0.0080 - accuracy: 0.9972"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 54s 31ms/step - loss: 0.0080 - accuracy: 0.9972 - val_loss: 0.0363 - val_accuracy: 0.9922\n",
            "Epoch 31/50\n",
            "1749/1750 [============================>.] - ETA: 0s - loss: 0.0072 - accuracy: 0.9977"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 53s 30ms/step - loss: 0.0072 - accuracy: 0.9977 - val_loss: 0.0450 - val_accuracy: 0.9914\n",
            "Epoch 32/50\n",
            "1749/1750 [============================>.] - ETA: 0s - loss: 0.0072 - accuracy: 0.9973"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 52s 30ms/step - loss: 0.0072 - accuracy: 0.9973 - val_loss: 0.0495 - val_accuracy: 0.9915\n",
            "Epoch 33/50\n",
            "1750/1750 [==============================] - ETA: 0s - loss: 0.0078 - accuracy: 0.9974"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 53s 30ms/step - loss: 0.0078 - accuracy: 0.9974 - val_loss: 0.0432 - val_accuracy: 0.9913\n",
            "Epoch 34/50\n",
            "1750/1750 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.9981"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 53s 30ms/step - loss: 0.0057 - accuracy: 0.9981 - val_loss: 0.0517 - val_accuracy: 0.9906\n",
            "Epoch 35/50\n",
            "1749/1750 [============================>.] - ETA: 0s - loss: 0.0075 - accuracy: 0.9976"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 54s 31ms/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.0419 - val_accuracy: 0.9920\n",
            "Epoch 36/50\n",
            "1748/1750 [============================>.] - ETA: 0s - loss: 0.0063 - accuracy: 0.9977"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 52s 30ms/step - loss: 0.0063 - accuracy: 0.9977 - val_loss: 0.0492 - val_accuracy: 0.9916\n",
            "Epoch 37/50\n",
            "1749/1750 [============================>.] - ETA: 0s - loss: 0.0074 - accuracy: 0.9973"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 50s 29ms/step - loss: 0.0074 - accuracy: 0.9973 - val_loss: 0.0480 - val_accuracy: 0.9911\n",
            "Epoch 38/50\n",
            "1749/1750 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.9979"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 54s 31ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.0464 - val_accuracy: 0.9923\n",
            "Epoch 39/50\n",
            "1750/1750 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 0.9978"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 54s 31ms/step - loss: 0.0069 - accuracy: 0.9978 - val_loss: 0.0448 - val_accuracy: 0.9923\n",
            "Epoch 40/50\n",
            "1750/1750 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 0.9981"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 52s 29ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 0.0458 - val_accuracy: 0.9914\n",
            "Epoch 41/50\n",
            "1750/1750 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9980"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 51s 29ms/step - loss: 0.0058 - accuracy: 0.9980 - val_loss: 0.0453 - val_accuracy: 0.9913\n",
            "Epoch 42/50\n",
            "1750/1750 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.9982"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 50s 28ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.0531 - val_accuracy: 0.9916\n",
            "Epoch 43/50\n",
            "1748/1750 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9979"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 49s 28ms/step - loss: 0.0060 - accuracy: 0.9979 - val_loss: 0.0508 - val_accuracy: 0.9921\n",
            "Epoch 44/50\n",
            "1749/1750 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9982"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 48s 27ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.0546 - val_accuracy: 0.9907\n",
            "Epoch 45/50\n",
            "1749/1750 [============================>.] - ETA: 0s - loss: 0.0076 - accuracy: 0.9973"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 50s 29ms/step - loss: 0.0076 - accuracy: 0.9973 - val_loss: 0.0560 - val_accuracy: 0.9910\n",
            "Epoch 46/50\n",
            "1750/1750 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9978"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 48s 27ms/step - loss: 0.0064 - accuracy: 0.9978 - val_loss: 0.0461 - val_accuracy: 0.9923\n",
            "Epoch 47/50\n",
            "1750/1750 [==============================] - ETA: 0s - loss: 0.0066 - accuracy: 0.9978"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 49s 28ms/step - loss: 0.0066 - accuracy: 0.9978 - val_loss: 0.0503 - val_accuracy: 0.9916\n",
            "Epoch 48/50\n",
            "1749/1750 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.9984"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 52s 29ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.0516 - val_accuracy: 0.9919\n",
            "Epoch 49/50\n",
            "1748/1750 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9983"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 49s 28ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.0493 - val_accuracy: 0.9916\n",
            "Epoch 50/50\n",
            "1748/1750 [============================>.] - ETA: 0s - loss: 0.0054 - accuracy: 0.9980"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 48s 28ms/step - loss: 0.0054 - accuracy: 0.9980 - val_loss: 0.0513 - val_accuracy: 0.9923\n",
            "438/438 [==============================] - 4s 8ms/step - loss: 0.0162 - accuracy: 0.9965\n",
            "Epoch 1/50\n",
            "1749/1750 [============================>.] - ETA: 0s - loss: 0.1837 - accuracy: 0.9447"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 52s 29ms/step - loss: 0.1837 - accuracy: 0.9447 - val_loss: 0.0643 - val_accuracy: 0.9801\n",
            "Epoch 2/50\n",
            "1749/1750 [============================>.] - ETA: 0s - loss: 0.0603 - accuracy: 0.9812"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 51s 29ms/step - loss: 0.0602 - accuracy: 0.9812 - val_loss: 0.0436 - val_accuracy: 0.9857\n",
            "Epoch 3/50\n",
            "1748/1750 [============================>.] - ETA: 0s - loss: 0.0493 - accuracy: 0.9848"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 51s 29ms/step - loss: 0.0493 - accuracy: 0.9848 - val_loss: 0.0382 - val_accuracy: 0.9874\n",
            "Epoch 4/50\n",
            "1748/1750 [============================>.] - ETA: 0s - loss: 0.0384 - accuracy: 0.9880"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 50s 28ms/step - loss: 0.0384 - accuracy: 0.9879 - val_loss: 0.0381 - val_accuracy: 0.9881\n",
            "Epoch 5/50\n",
            "1749/1750 [============================>.] - ETA: 0s - loss: 0.0332 - accuracy: 0.9897"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 52s 29ms/step - loss: 0.0332 - accuracy: 0.9897 - val_loss: 0.0328 - val_accuracy: 0.9897\n",
            "Epoch 6/50\n",
            "1749/1750 [============================>.] - ETA: 0s - loss: 0.0282 - accuracy: 0.9910"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 51s 29ms/step - loss: 0.0282 - accuracy: 0.9910 - val_loss: 0.0374 - val_accuracy: 0.9883\n",
            "Epoch 7/50\n",
            "1750/1750 [==============================] - ETA: 0s - loss: 0.0258 - accuracy: 0.9916"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 49s 28ms/step - loss: 0.0258 - accuracy: 0.9916 - val_loss: 0.0322 - val_accuracy: 0.9901\n",
            "Epoch 8/50\n",
            "1750/1750 [==============================] - ETA: 0s - loss: 0.0228 - accuracy: 0.9923"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 48s 28ms/step - loss: 0.0228 - accuracy: 0.9923 - val_loss: 0.0336 - val_accuracy: 0.9896\n",
            "Epoch 9/50\n",
            "1750/1750 [==============================] - ETA: 0s - loss: 0.0214 - accuracy: 0.9927"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 49s 28ms/step - loss: 0.0214 - accuracy: 0.9927 - val_loss: 0.0315 - val_accuracy: 0.9901\n",
            "Epoch 10/50\n",
            "1749/1750 [============================>.] - ETA: 0s - loss: 0.0190 - accuracy: 0.9939"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 49s 28ms/step - loss: 0.0190 - accuracy: 0.9939 - val_loss: 0.0335 - val_accuracy: 0.9903\n",
            "Epoch 11/50\n",
            "1750/1750 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 0.9943"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 50s 29ms/step - loss: 0.0177 - accuracy: 0.9943 - val_loss: 0.0390 - val_accuracy: 0.9886\n",
            "Epoch 12/50\n",
            "1750/1750 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 0.9950"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 50s 28ms/step - loss: 0.0152 - accuracy: 0.9950 - val_loss: 0.0329 - val_accuracy: 0.9899\n",
            "Epoch 13/50\n",
            "1750/1750 [==============================] - ETA: 0s - loss: 0.0147 - accuracy: 0.9950"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 49s 28ms/step - loss: 0.0147 - accuracy: 0.9950 - val_loss: 0.0315 - val_accuracy: 0.9914\n",
            "Epoch 14/50\n",
            "1750/1750 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.9949"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 50s 28ms/step - loss: 0.0148 - accuracy: 0.9949 - val_loss: 0.0315 - val_accuracy: 0.9906\n",
            "Epoch 15/50\n",
            "1750/1750 [==============================] - ETA: 0s - loss: 0.0134 - accuracy: 0.9954"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 50s 29ms/step - loss: 0.0134 - accuracy: 0.9954 - val_loss: 0.0370 - val_accuracy: 0.9901\n",
            "Epoch 16/50\n",
            "1750/1750 [==============================] - ETA: 0s - loss: 0.0125 - accuracy: 0.9957"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 50s 29ms/step - loss: 0.0125 - accuracy: 0.9957 - val_loss: 0.0355 - val_accuracy: 0.9909\n",
            "Epoch 17/50\n",
            "1750/1750 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 0.9962"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 48s 27ms/step - loss: 0.0111 - accuracy: 0.9962 - val_loss: 0.0331 - val_accuracy: 0.9909\n",
            "Epoch 18/50\n",
            "1750/1750 [==============================] - ETA: 0s - loss: 0.0122 - accuracy: 0.9958"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 49s 28ms/step - loss: 0.0122 - accuracy: 0.9958 - val_loss: 0.0328 - val_accuracy: 0.9909\n",
            "Epoch 19/50\n",
            "1749/1750 [============================>.] - ETA: 0s - loss: 0.0111 - accuracy: 0.9961"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 51s 29ms/step - loss: 0.0111 - accuracy: 0.9961 - val_loss: 0.0339 - val_accuracy: 0.9910\n",
            "Epoch 20/50\n",
            "1750/1750 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.9963"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 50s 29ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.0336 - val_accuracy: 0.9911\n",
            "Epoch 21/50\n",
            "1750/1750 [==============================] - ETA: 0s - loss: 0.0099 - accuracy: 0.9967"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 51s 29ms/step - loss: 0.0099 - accuracy: 0.9967 - val_loss: 0.0356 - val_accuracy: 0.9913\n",
            "Epoch 22/50\n",
            "1750/1750 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9968"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 49s 28ms/step - loss: 0.0092 - accuracy: 0.9968 - val_loss: 0.0378 - val_accuracy: 0.9911\n",
            "Epoch 23/50\n",
            "1749/1750 [============================>.] - ETA: 0s - loss: 0.0081 - accuracy: 0.9973"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 49s 28ms/step - loss: 0.0081 - accuracy: 0.9973 - val_loss: 0.0381 - val_accuracy: 0.9911\n",
            "Epoch 24/50\n",
            "1750/1750 [==============================] - ETA: 0s - loss: 0.0102 - accuracy: 0.9967"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 49s 28ms/step - loss: 0.0102 - accuracy: 0.9967 - val_loss: 0.0363 - val_accuracy: 0.9911\n",
            "Epoch 25/50\n",
            "1750/1750 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 0.9971"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 50s 29ms/step - loss: 0.0082 - accuracy: 0.9971 - val_loss: 0.0335 - val_accuracy: 0.9916\n",
            "Epoch 26/50\n",
            "1749/1750 [============================>.] - ETA: 0s - loss: 0.0086 - accuracy: 0.9972"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 51s 29ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 0.0361 - val_accuracy: 0.9904\n",
            "Epoch 27/50\n",
            "1749/1750 [============================>.] - ETA: 0s - loss: 0.0085 - accuracy: 0.9970"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 50s 28ms/step - loss: 0.0085 - accuracy: 0.9970 - val_loss: 0.0354 - val_accuracy: 0.9916\n",
            "Epoch 28/50\n",
            "1750/1750 [==============================] - ETA: 0s - loss: 0.0081 - accuracy: 0.9973"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 50s 29ms/step - loss: 0.0081 - accuracy: 0.9973 - val_loss: 0.0340 - val_accuracy: 0.9920\n",
            "Epoch 29/50\n",
            "1749/1750 [============================>.] - ETA: 0s - loss: 0.0072 - accuracy: 0.9973"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 49s 28ms/step - loss: 0.0072 - accuracy: 0.9973 - val_loss: 0.0442 - val_accuracy: 0.9905\n",
            "Epoch 30/50\n",
            "1750/1750 [==============================] - ETA: 0s - loss: 0.0066 - accuracy: 0.9976"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 49s 28ms/step - loss: 0.0066 - accuracy: 0.9976 - val_loss: 0.0413 - val_accuracy: 0.9902\n",
            "Epoch 31/50\n",
            "1750/1750 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9979"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 49s 28ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.0380 - val_accuracy: 0.9906\n",
            "Epoch 32/50\n",
            "1749/1750 [============================>.] - ETA: 0s - loss: 0.0074 - accuracy: 0.9974"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 53s 31ms/step - loss: 0.0074 - accuracy: 0.9974 - val_loss: 0.0454 - val_accuracy: 0.9898\n",
            "Epoch 33/50\n",
            "1750/1750 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9978"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 51s 29ms/step - loss: 0.0063 - accuracy: 0.9978 - val_loss: 0.0393 - val_accuracy: 0.9911\n",
            "Epoch 34/50\n",
            "1750/1750 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 0.9974"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 51s 29ms/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.0427 - val_accuracy: 0.9902\n",
            "Epoch 35/50\n",
            "1750/1750 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9978"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 50s 28ms/step - loss: 0.0063 - accuracy: 0.9978 - val_loss: 0.0390 - val_accuracy: 0.9918\n",
            "Epoch 36/50\n",
            "1748/1750 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9979"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 51s 29ms/step - loss: 0.0060 - accuracy: 0.9979 - val_loss: 0.0458 - val_accuracy: 0.9913\n",
            "Epoch 37/50\n",
            "1749/1750 [============================>.] - ETA: 0s - loss: 0.0072 - accuracy: 0.9975"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 49s 28ms/step - loss: 0.0072 - accuracy: 0.9975 - val_loss: 0.0400 - val_accuracy: 0.9914\n",
            "Epoch 38/50\n",
            "1750/1750 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 0.9978"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 50s 29ms/step - loss: 0.0060 - accuracy: 0.9978 - val_loss: 0.0433 - val_accuracy: 0.9909\n",
            "Epoch 39/50\n",
            "1748/1750 [============================>.] - ETA: 0s - loss: 0.0070 - accuracy: 0.9977"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 48s 27ms/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.0403 - val_accuracy: 0.9904\n",
            "Epoch 40/50\n",
            "1750/1750 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.9981"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 48s 28ms/step - loss: 0.0056 - accuracy: 0.9981 - val_loss: 0.0463 - val_accuracy: 0.9906\n",
            "Epoch 41/50\n",
            "1749/1750 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9981"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 51s 29ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.0480 - val_accuracy: 0.9909\n",
            "Epoch 42/50\n",
            "1750/1750 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 0.9982"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 48s 28ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.0446 - val_accuracy: 0.9920\n",
            "Epoch 43/50\n",
            "1749/1750 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9980"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 50s 29ms/step - loss: 0.0059 - accuracy: 0.9980 - val_loss: 0.0457 - val_accuracy: 0.9906\n",
            "Epoch 44/50\n",
            "1748/1750 [============================>.] - ETA: 0s - loss: 0.0049 - accuracy: 0.9984"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 49s 28ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.0447 - val_accuracy: 0.9914\n",
            "Epoch 45/50\n",
            "1749/1750 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.9977"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 51s 29ms/step - loss: 0.0064 - accuracy: 0.9977 - val_loss: 0.0494 - val_accuracy: 0.9911\n",
            "Epoch 46/50\n",
            "1750/1750 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 0.9981"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 49s 28ms/step - loss: 0.0055 - accuracy: 0.9981 - val_loss: 0.0438 - val_accuracy: 0.9914\n",
            "Epoch 47/50\n",
            "1750/1750 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9983"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 49s 28ms/step - loss: 0.0051 - accuracy: 0.9983 - val_loss: 0.0526 - val_accuracy: 0.9902\n",
            "Epoch 48/50\n",
            "1749/1750 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9978"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 49s 28ms/step - loss: 0.0058 - accuracy: 0.9978 - val_loss: 0.0502 - val_accuracy: 0.9909\n",
            "Epoch 49/50\n",
            "1750/1750 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9978"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 49s 28ms/step - loss: 0.0058 - accuracy: 0.9978 - val_loss: 0.0545 - val_accuracy: 0.9904\n",
            "Epoch 50/50\n",
            "1748/1750 [============================>.] - ETA: 0s - loss: 0.0067 - accuracy: 0.9978"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 51s 29ms/step - loss: 0.0067 - accuracy: 0.9978 - val_loss: 0.0469 - val_accuracy: 0.9903\n",
            "438/438 [==============================] - 4s 8ms/step - loss: 0.0198 - accuracy: 0.9961\n",
            "Epoch 1/50\n",
            "1750/1750 [==============================] - ETA: 0s - loss: 0.1850 - accuracy: 0.9438"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 53s 30ms/step - loss: 0.1850 - accuracy: 0.9438 - val_loss: 0.0763 - val_accuracy: 0.9759\n",
            "Epoch 2/50\n",
            "1750/1750 [==============================] - ETA: 0s - loss: 0.0651 - accuracy: 0.9795"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 50s 29ms/step - loss: 0.0651 - accuracy: 0.9795 - val_loss: 0.0605 - val_accuracy: 0.9807\n",
            "Epoch 3/50\n",
            "1749/1750 [============================>.] - ETA: 0s - loss: 0.0482 - accuracy: 0.9850"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 51s 29ms/step - loss: 0.0482 - accuracy: 0.9850 - val_loss: 0.0476 - val_accuracy: 0.9850\n",
            "Epoch 4/50\n",
            "1749/1750 [============================>.] - ETA: 0s - loss: 0.0403 - accuracy: 0.9873"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1750/1750 [==============================] - 52s 30ms/step - loss: 0.0403 - accuracy: 0.9873 - val_loss: 0.0413 - val_accuracy: 0.9874\n",
            "Epoch 5/50\n",
            "1416/1750 [=======================>......] - ETA: 9s - loss: 0.0344 - accuracy: 0.9893"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Concatenate the training and testing data for cross-validation\n",
        "X_all = np.concatenate((X_train, X_test), axis=0)\n",
        "y_all = np.concatenate((y_train, y_test), axis=0)\n",
        "\n",
        "# Define the number of folds for cross-validation\n",
        "n_splits = 5  # You can adjust this based on your preference\n",
        "\n",
        "# Initialize the StratifiedKFold object\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "# Lists to store accuracy for each fold\n",
        "accuracies = []\n",
        "\n",
        "# Iterate through the folds\n",
        "for train_index, val_index in skf.split(X_all, np.argmax(y_all, axis=1)):\n",
        "    # Split the data into training and validation sets\n",
        "    X_train_fold, X_val_fold = X_all[train_index], X_all[val_index]\n",
        "    y_train_fold, y_val_fold = y_all[train_index], y_all[val_index]\n",
        "\n",
        "    # Create a new model for each fold\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3,3), input_shape=(28, 28,1), activation='relu'))\n",
        "    model.add(MaxPool2D((2, 2)))\n",
        "    model.add(Conv2D(64, (3,3), activation='relu'))\n",
        "    model.add(MaxPool2D((2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "    model.compile(optimizer='adam', loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
        "\n",
        "    # Fit the model on the training data for this fold\n",
        "    model.fit(X_train_fold, y_train_fold, epochs=50, validation_data=(X_val_fold, y_val_fold), callbacks=[es, mc])\n",
        "\n",
        "    # Load the best model saved during training\n",
        "    model.load_weights(\"./bestmodel.h5\")\n",
        "\n",
        "    # Evaluate the model on the validation set\n",
        "    val_loss, val_acc = model.evaluate(X_val_fold, y_val_fold)\n",
        "    accuracies.append(val_acc)\n",
        "\n",
        "# Print the accuracies for each fold\n",
        "for i, acc in enumerate(accuracies):\n",
        "    print(f\"Fold {i+1} Accuracy: {acc}\")\n",
        "\n",
        "# Print the average accuracy across all folds\n",
        "print(f\"Average Accuracy: {np.mean(accuracies)}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}